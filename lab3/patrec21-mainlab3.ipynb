{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Recognition - Flow S\n",
    "## Lab 3 (Main): Genre and Emotion Recognition from Music\n",
    "### Dimitris Dimos - 031 17 165\n",
    "### Konstantinos Kopsinis - 031 17 062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-28T22:54:36.440935Z",
     "iopub.status.busy": "2022-02-28T22:54:36.440576Z",
     "iopub.status.idle": "2022-02-28T22:54:39.515244Z",
     "shell.execute_reply": "2022-02-28T22:54:39.514533Z",
     "shell.execute_reply.started": "2022-02-28T22:54:36.440891Z"
    }
   },
   "outputs": [],
   "source": [
    "## packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import csv\n",
    "from matplotlib.colors import ListedColormap\n",
    "from librosa.display import specshow\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:54:39.51956Z",
     "iopub.status.busy": "2022-02-28T22:54:39.517692Z",
     "iopub.status.idle": "2022-02-28T22:54:39.523892Z",
     "shell.execute_reply": "2022-02-28T22:54:39.522703Z",
     "shell.execute_reply.started": "2022-02-28T22:54:39.519519Z"
    }
   },
   "outputs": [],
   "source": [
    "# data directories\n",
    "fma_genre_spectrograms = \"/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/\"\n",
    "fma_genre_spectrograms_beat = \"/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/\"\n",
    "multitask_dataset = \"/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/\"\n",
    "multitask_dataset_beat = \"/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset_beat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:54:39.525497Z",
     "iopub.status.busy": "2022-02-28T22:54:39.525203Z",
     "iopub.status.idle": "2022-02-28T22:54:40.254774Z",
     "shell.execute_reply": "2022-02-28T22:54:40.253924Z",
     "shell.execute_reply.started": "2022-02-28T22:54:39.525463Z"
    }
   },
   "outputs": [],
   "source": [
    "# we now import the auxiliary code from github\n",
    "!cp -r /kaggle/input/lab3-aux/* ./\n",
    "import dataset\n",
    "import dataset2\n",
    "import multitask_dataset\n",
    "import lab2_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:54:40.256476Z",
     "iopub.status.busy": "2022-02-28T22:54:40.25619Z",
     "iopub.status.idle": "2022-02-28T22:54:40.269919Z",
     "shell.execute_reply": "2022-02-28T22:54:40.268838Z",
     "shell.execute_reply.started": "2022-02-28T22:54:40.256438Z"
    }
   },
   "outputs": [],
   "source": [
    "# definition of Custom CNN\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN,self).__init__()\n",
    "        self._cnn_module = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=4),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=4)\n",
    "        )\n",
    "\n",
    "        ## Kaggle Competition\n",
    "#         self._cnn_module = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "#             nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "#             nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "#             nn.Conv2d(in_channels=128, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "        self._fc_module = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=20480, out_features=1) #10240\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=x.transpose(1,2)\n",
    "        x=torch.unsqueeze(x,1)\n",
    "        x = self._cnn_module(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self._fc_module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:54:40.272894Z",
     "iopub.status.busy": "2022-02-28T22:54:40.272642Z",
     "iopub.status.idle": "2022-02-28T22:54:40.316696Z",
     "shell.execute_reply": "2022-02-28T22:54:40.315924Z",
     "shell.execute_reply.started": "2022-02-28T22:54:40.272861Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:06:03.473379Z",
     "iopub.status.busy": "2022-02-28T22:06:03.47283Z",
     "iopub.status.idle": "2022-02-28T22:06:03.486349Z",
     "shell.execute_reply": "2022-02-28T22:06:03.485577Z",
     "shell.execute_reply.started": "2022-02-28T22:06:03.473288Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion, regression=False, lstm=False):\n",
    "    model.eval() # switch to evaluation mode: disable dropout\n",
    "    overall_loss = 0.0\n",
    "    DEVICE = next(model.parameters()).device # set DEVICE to the model's predefined device\n",
    "    \n",
    "    y_pred = [] # predicted labels\n",
    "    y_gold = [] # gold labels\n",
    "    \n",
    "    with torch.no_grad(): # do not compute gradients\n",
    "        for idx, batch in enumerate(dataloader, 1):\n",
    "            \n",
    "            inputs  = batch[0].to(DEVICE).float()\n",
    "            if regression:\n",
    "                labels  = batch[1].to(DEVICE).float()\n",
    "            else:\n",
    "                labels  = batch[1].to(DEVICE).long()\n",
    "                \n",
    "            if not lstm:\n",
    "                y_preds = model(inputs)#, lengths)  # forward pass\n",
    "            else:\n",
    "                inputs  = batch[0].to(DEVICE).double()\n",
    "                labels  = batch[1].to(DEVICE).double()\n",
    "                lengths = batch[2].to(DEVICE)\n",
    "                y_preds = model(inputs, lengths)\n",
    "            \n",
    "            if not regression:\n",
    "                loss = criterion(y_preds, labels)\n",
    "            else:\n",
    "                loss = criterion(y_preds.squeeze(), labels)\n",
    "                \n",
    "            if not regression:\n",
    "                prediction = torch.argmax(y_preds, dim=1) # predict\n",
    "            else:\n",
    "                prediction = y_preds\n",
    "            \n",
    "            overall_loss += loss.data.item()\n",
    "            \n",
    "            y_pred.append(prediction.cpu().numpy())\n",
    "            y_gold.append(labels.cpu().numpy())\n",
    "\n",
    "    return overall_loss/idx, (y_gold, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T21:02:01.706908Z",
     "iopub.status.busy": "2022-02-28T21:02:01.706617Z",
     "iopub.status.idle": "2022-02-28T21:02:01.726975Z",
     "shell.execute_reply": "2022-02-28T21:02:01.726151Z",
     "shell.execute_reply.started": "2022-02-28T21:02:01.706856Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_cnn(train_loader, val_loader, save_string, epochs, regression=False, early_stopping=True, transfer=False):\n",
    "    \n",
    "    model_cnn = CustomCNN().to(DEVICE).float()\n",
    "    \n",
    "    if not regression:\n",
    "        model_cnn._fc_module = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=10240, out_features=10) #10240\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "    else:\n",
    "        model_cnn._fc_module = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=10240, out_features=1) #10240\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "    if transfer:\n",
    "        model_cnn = CustomCNN().to(DEVICE).float()\n",
    "        model_cnn._fc_module = nn.Sequential(\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(in_features=10240, out_features=10) #10240\n",
    "                ).to(DEVICE)\n",
    "        model_cnn.load_state_dict(torch.load(\"step7\"))\n",
    "        \n",
    "        for weight in model_cnn.parameters():\n",
    "            weight.requires_grad = False\n",
    "\n",
    "        # this one by default stays trainable\n",
    "        model_cnn._fc_module = nn.Sequential(\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(in_features=10240, out_features=1) #10240\n",
    "                ).to(DEVICE)\n",
    "        save_string = \"step9\"\n",
    "    \n",
    "    batch_size=BATCH_SIZE\n",
    "    output_dim = 1\n",
    "\n",
    "    lr=LR\n",
    "    if not regression:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model_cnn.parameters(), lr=lr, weight_decay=0.0001)\n",
    "\n",
    "    train_loss_min = np.Inf\n",
    "    loss_values_train = []\n",
    "    loss_values_val = []\n",
    "    count=0\n",
    "    \n",
    "    opt_val_loss = np.Inf\n",
    "    \n",
    "    model_cnn.train()    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss_train=0.0\n",
    "        #running_loss_val=0.0\n",
    "        train_losses=[]\n",
    "        for inputs, labels,lengths in train_loader:\n",
    "            inputs, labels, lengths= inputs.to(DEVICE), labels.to(DEVICE), lengths.to(DEVICE)\n",
    "            model_cnn.zero_grad()\n",
    "            output =  model_cnn(inputs.float())\n",
    "            \n",
    "            if not regression:\n",
    "                loss = criterion(output, labels.long())\n",
    "            else:\n",
    "                loss = criterion(output.squeeze(), labels.float())\n",
    "                \n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        val_loss, (y_gold, y_pred) = evaluate_model(model_cnn, val_loader, criterion, regression)\n",
    "        \n",
    "        if val_loss < opt_val_loss:\n",
    "            opt_val_loss = val_loss\n",
    "            torch.save(model_cnn.state_dict(), save_string)\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "            \n",
    "        loss_values_train.append(np.mean(train_losses))\n",
    "        loss_values_val.append(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch}: \\t Training Loss = {loss_values_train[-1]} \\t--\\t Validation Loss = {loss_values_val[-1]}')\n",
    "        if count > 7 and early_stopping:\n",
    "            print(\"Terminated due to early stopping\")\n",
    "            break\n",
    "            \n",
    "    if not early_stopping:\n",
    "        torch.save(model_cnn.state_dict(), save_string)\n",
    "            \n",
    "    return loss_values_train, loss_values_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:42:03.958175Z",
     "iopub.status.busy": "2022-02-28T01:42:03.957479Z",
     "iopub.status.idle": "2022-02-28T01:42:51.735195Z",
     "shell.execute_reply": "2022-02-28T01:42:51.73429Z",
     "shell.execute_reply.started": "2022-02-28T01:42:03.958122Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data - Mel Spectrograms\n",
    "mel_spectro_dataset = dataset.SpectrogramDataset(fma_genre_spectrograms,\n",
    "                                                 train=True,\n",
    "                                                 class_mapping=dataset.CLASS_MAPPING,\n",
    "                                                 max_length=-1,\n",
    "                                                 read_spec_fn=dataset.read_mel_spectrogram#read_mel_spectrogram\n",
    "                                                )\n",
    "# train and validation sets\n",
    "train_loader, val_loader = dataset.torch_train_val_split(mel_spectro_dataset, BATCH_SIZE, BATCH_SIZE, val_size=.33)\n",
    "\n",
    "# test set\n",
    "ttest_loader_ = dataset.SpectrogramDataset(fma_genre_spectrograms,\n",
    "                                           train=False,\n",
    "                                           class_mapping=dataset.CLASS_MAPPING,\n",
    "                                           max_length=-1,\n",
    "                                           read_spec_fn=dataset.read_mel_spectrogram#read_mel_spectrogram\n",
    "                                          )\n",
    "ttest_loader = DataLoader(ttest_loader_, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T17:45:18.76462Z",
     "iopub.status.busy": "2022-02-27T17:45:18.764093Z",
     "iopub.status.idle": "2022-02-27T17:45:20.092906Z",
     "shell.execute_reply": "2022-02-27T17:45:20.091409Z",
     "shell.execute_reply.started": "2022-02-27T17:45:18.76458Z"
    }
   },
   "outputs": [],
   "source": [
    "# overfit batch\n",
    "subset = torch.utils.data.Subset(mel_spectro_dataset, [i for i in range(16)])\n",
    "overfit_loader = DataLoader(subset, batch_size=2)\n",
    "_ = train_cnn(train_loader = overfit_loader,\n",
    "          val_loader = overfit_loader,\n",
    "          save_string=\"dummy\",\n",
    "          epochs=10,\n",
    "          regression=False,\n",
    "          early_stopping = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:42:51.737764Z",
     "iopub.status.busy": "2022-02-28T01:42:51.737205Z",
     "iopub.status.idle": "2022-02-28T01:45:38.41896Z",
     "shell.execute_reply": "2022-02-28T01:45:38.417471Z",
     "shell.execute_reply.started": "2022-02-28T01:42:51.737723Z"
    }
   },
   "outputs": [],
   "source": [
    "# real training\n",
    "loss_values_train, loss_values_val = train_cnn(train_loader = train_loader,\n",
    "                                               val_loader = val_loader,\n",
    "                                               save_string=\"step7\",\n",
    "                                               epochs=EPOCHS,\n",
    "                                               regression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:31:16.506548Z",
     "iopub.status.busy": "2022-02-28T19:31:16.506294Z",
     "iopub.status.idle": "2022-02-28T19:31:16.513481Z",
     "shell.execute_reply": "2022-02-28T19:31:16.512743Z",
     "shell.execute_reply.started": "2022-02-28T19:31:16.506518Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_report_CNN(model, test_loader, model_dir, regression = False):\n",
    "    \n",
    "    if not regression:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        model._fc_module = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=10240, out_features=10) #10240\n",
    "        ).to(DEVICE)\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "        model._fc_module = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=10240, out_features=1) #10240\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "    model.load_state_dict(torch.load(model_dir))\n",
    "        \n",
    "    test_loss, (y_gold, y_pred) = evaluate_model(model, test_loader, criterion, regression)\n",
    "    print(classification_report(np.concatenate(y_gold), np.concatenate(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:45:38.430633Z",
     "iopub.status.busy": "2022-02-28T01:45:38.430196Z",
     "iopub.status.idle": "2022-02-28T01:45:40.055423Z",
     "shell.execute_reply": "2022-02-28T01:45:40.054687Z",
     "shell.execute_reply.started": "2022-02-28T01:45:38.430598Z"
    }
   },
   "outputs": [],
   "source": [
    "test_report_CNN(CustomCNN().to(DEVICE), ttest_loader, \"step7\", regression=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Emotion-Behavior Estimation with Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:54:40.319041Z",
     "iopub.status.busy": "2022-02-28T22:54:40.318665Z",
     "iopub.status.idle": "2022-02-28T22:54:40.328237Z",
     "shell.execute_reply": "2022-02-28T22:54:40.327449Z",
     "shell.execute_reply.started": "2022-02-28T22:54:40.319007Z"
    }
   },
   "outputs": [],
   "source": [
    "multitask_dir = \"/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/\"\n",
    "multitask_beat_dir = \"/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset_beat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:06:44.784661Z",
     "iopub.status.busy": "2022-02-28T01:06:44.78437Z",
     "iopub.status.idle": "2022-02-28T01:07:06.364018Z",
     "shell.execute_reply": "2022-02-28T01:07:06.363223Z",
     "shell.execute_reply.started": "2022-02-28T01:06:44.784618Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_valence = dataset2.SpectrogramDataset(multitask_dir,\n",
    "                                      train=True,\n",
    "                                      class_mapping=dataset.CLASS_MAPPING,\n",
    "                                      max_length=-1,\n",
    "                                      regression=1\n",
    "                                      )\n",
    "# train and validation sets\n",
    "train_loader_valence, val_loader_valence = dataset2.torch_train_val_split(dataset_valence,\n",
    "                                                                          batch_train=32,\n",
    "                                                                          batch_eval=32,\n",
    "                                                                          val_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T20:20:17.10193Z",
     "iopub.status.busy": "2022-02-28T20:20:17.101487Z",
     "iopub.status.idle": "2022-02-28T20:20:17.114731Z",
     "shell.execute_reply": "2022-02-28T20:20:17.114055Z",
     "shell.execute_reply.started": "2022-02-28T20:20:17.101893Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_cnn_model_multitask(test_loader, save_file):\n",
    "    model_cnn = CustomCNN().to(DEVICE)\n",
    "    \n",
    "    model_cnn._fc_module = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=10240, out_features=1) #10240\n",
    "        ).to(DEVICE)\n",
    "    \n",
    "    \n",
    "    model_cnn.load_state_dict(torch.load(save_file))\n",
    "    \n",
    "    batch_size=5\n",
    "    test_losses = []\n",
    "    y_pred_test=[]\n",
    "    y_true=[]\n",
    "    model_cnn.eval()\n",
    "    \n",
    "    for inputs, labels,lengths in test_loader:\n",
    "        inputs,labels,lengths= inputs.to(DEVICE), labels.to(DEVICE), lengths.to(DEVICE)\n",
    "        output = model_cnn(inputs.float())\n",
    "        y_pred_test.append(output.data.tolist())\n",
    "        y_true.append(labels.tolist())\n",
    "    rho= scipy.stats.spearmanr(np.array(y_true).flatten(),np.array(y_pred_test).flatten()).correlation\n",
    "    print('\\nTest set: Spearman Correlation: {:.6f} \\n'.format(rho))\n",
    "    \n",
    "    true = np.array(y_true).flatten()\n",
    "    pred = np.array(y_pred_test).flatten()\n",
    "    \n",
    "    # Scatter Plot Predictions - Gold Labels\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(true, pred)\n",
    "    plt.xlabel('y_true')\n",
    "    plt.ylabel('y_pred')\n",
    "    golden_line = np.linspace(0,1,1000)\n",
    "    plt.plot(golden_line,golden_line, '-', color='k')\n",
    "    plt.show()\n",
    "    \n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T17:53:50.573369Z",
     "iopub.status.busy": "2022-02-27T17:53:50.572569Z",
     "iopub.status.idle": "2022-02-27T17:56:33.899944Z",
     "shell.execute_reply": "2022-02-27T17:56:33.89915Z",
     "shell.execute_reply.started": "2022-02-27T17:53:50.57332Z"
    }
   },
   "outputs": [],
   "source": [
    "# valence training\n",
    "train_loss_valence, _ = train_cnn(train_loader = train_loader_valence,\n",
    "                                               val_loader = val_loader_valence,\n",
    "                                               save_string=\"valence_CNN\",\n",
    "                                               epochs=EPOCHS,\n",
    "                                               regression=True,\n",
    "                                               early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T18:02:37.817605Z",
     "iopub.status.busy": "2022-02-27T18:02:37.817235Z",
     "iopub.status.idle": "2022-02-27T18:02:38.809249Z",
     "shell.execute_reply": "2022-02-27T18:02:38.808585Z",
     "shell.execute_reply.started": "2022-02-27T18:02:37.817569Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_spear = test_cnn_model_multitask(val_loader_valence, \"valence_CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:55:06.788659Z",
     "iopub.status.busy": "2022-02-28T01:55:06.788411Z",
     "iopub.status.idle": "2022-02-28T01:55:24.649664Z",
     "shell.execute_reply": "2022-02-28T01:55:24.648825Z",
     "shell.execute_reply.started": "2022-02-28T01:55:06.788631Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_energy = dataset2.SpectrogramDataset(multitask_dir,\n",
    "                                             train=True,\n",
    "                                             class_mapping=dataset.CLASS_MAPPING,\n",
    "                                             max_length=-1,\n",
    "                                             regression=2\n",
    "                                             )\n",
    "# train and validation sets\n",
    "train_loader_energy, val_loader_energy = dataset2.torch_train_val_split(dataset_energy,\n",
    "                                                                          batch_train=32,\n",
    "                                                                          batch_eval=32,\n",
    "                                                                          val_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T18:07:11.501377Z",
     "iopub.status.busy": "2022-02-27T18:07:11.501169Z",
     "iopub.status.idle": "2022-02-27T18:10:03.052538Z",
     "shell.execute_reply": "2022-02-27T18:10:03.051797Z",
     "shell.execute_reply.started": "2022-02-27T18:07:11.501353Z"
    }
   },
   "outputs": [],
   "source": [
    "# energy training\n",
    "train_loss_energy, _ = train_cnn(train_loader = train_loader_energy,\n",
    "                                               val_loader = val_loader_energy,\n",
    "                                               save_string=\"energy_CNN\",\n",
    "                                               epochs=EPOCHS,\n",
    "                                               regression=True,\n",
    "                                               early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T18:11:45.080391Z",
     "iopub.status.busy": "2022-02-27T18:11:45.079573Z",
     "iopub.status.idle": "2022-02-27T18:11:46.047223Z",
     "shell.execute_reply": "2022-02-27T18:11:46.045897Z",
     "shell.execute_reply.started": "2022-02-27T18:11:45.080347Z"
    }
   },
   "outputs": [],
   "source": [
    "energy_spear = test_cnn_model_multitask(val_loader_energy, \"energy_CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:07:12.166167Z",
     "iopub.status.busy": "2022-02-28T01:07:12.165528Z",
     "iopub.status.idle": "2022-02-28T01:07:14.062097Z",
     "shell.execute_reply": "2022-02-28T01:07:14.061367Z",
     "shell.execute_reply.started": "2022-02-28T01:07:12.166126Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dancability = dataset2.SpectrogramDataset(multitask_dir,\n",
    "                                             train=True,\n",
    "                                             class_mapping=dataset.CLASS_MAPPING,\n",
    "                                             max_length=-1,\n",
    "                                             regression=3\n",
    "                                             )\n",
    "# train and validation sets\n",
    "train_loader_dancability, val_loader_dancability = dataset2.torch_train_val_split(dataset_dancability,\n",
    "                                                                          batch_train=32,\n",
    "                                                                          batch_eval=32,\n",
    "                                                                          val_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T18:11:56.102216Z",
     "iopub.status.busy": "2022-02-27T18:11:56.101969Z",
     "iopub.status.idle": "2022-02-27T18:14:38.771689Z",
     "shell.execute_reply": "2022-02-27T18:14:38.77093Z",
     "shell.execute_reply.started": "2022-02-27T18:11:56.102183Z"
    }
   },
   "outputs": [],
   "source": [
    "# dancability training\n",
    "train_loss_dancability, _ = train_cnn(train_loader = train_loader_dancability,\n",
    "                                               val_loader = val_loader_dancability,\n",
    "                                               save_string=\"dancability_CNN\",\n",
    "                                               epochs=EPOCHS,\n",
    "                                               regression=True,\n",
    "                                               early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T18:14:38.774934Z",
     "iopub.status.busy": "2022-02-27T18:14:38.77311Z",
     "iopub.status.idle": "2022-02-27T18:14:39.707801Z",
     "shell.execute_reply": "2022-02-27T18:14:39.707056Z",
     "shell.execute_reply.started": "2022-02-27T18:14:38.774891Z"
    }
   },
   "outputs": [],
   "source": [
    "dancability_spear = test_cnn_model_multitask(val_loader_dancability, \"dancability_CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T18:16:41.959106Z",
     "iopub.status.busy": "2022-02-27T18:16:41.95883Z",
     "iopub.status.idle": "2022-02-27T18:16:41.964488Z",
     "shell.execute_reply": "2022-02-27T18:16:41.963819Z",
     "shell.execute_reply.started": "2022-02-27T18:16:41.959075Z"
    }
   },
   "outputs": [],
   "source": [
    "print((valence_spear + energy_spear + dancability_spear)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the same for the LSTM of lab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T02:56:41.713416Z",
     "iopub.status.busy": "2022-02-28T02:56:41.713132Z",
     "iopub.status.idle": "2022-02-28T02:56:41.71782Z",
     "shell.execute_reply": "2022-02-28T02:56:41.716884Z",
     "shell.execute_reply.started": "2022-02-28T02:56:41.713387Z"
    }
   },
   "outputs": [],
   "source": [
    "RNN_SIZE = 128\n",
    "NUM_LAYERS = 4\n",
    "n_mel = 140\n",
    "EPOCHS = 30\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T02:56:43.837427Z",
     "iopub.status.busy": "2022-02-28T02:56:43.836597Z",
     "iopub.status.idle": "2022-02-28T02:56:43.849203Z",
     "shell.execute_reply": "2022-02-28T02:56:43.848354Z",
     "shell.execute_reply.started": "2022-02-28T02:56:43.83738Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_lstm(train_loader, val_loader, save_string, early_stopping=True):\n",
    "    \n",
    "    model_lstm = lab2_lstm.CustomLSTM(input_dim=n_mel,\n",
    "                                      rnn_size=RNN_SIZE,\n",
    "                                      output_dim=1,\n",
    "                                      num_layers=NUM_LAYERS,\n",
    "                                      bidirectional=True,\n",
    "                                      dropout=0).double().to(DEVICE)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model_lstm.parameters(), lr=lr, weight_decay=0.0001)\n",
    "\n",
    "    loss_values_train = []\n",
    "    loss_values_val = []\n",
    "    count=0\n",
    "    opt_val_loss = np.Inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss_train=0.0\n",
    "        train_losses=[]\n",
    "        \n",
    "        for inputs, labels, lengths in train_loader:\n",
    "            model_lstm.train()   \n",
    "            inputs, labels, lengths = inputs.to(DEVICE), labels.to(DEVICE), lengths.to(DEVICE)\n",
    "            \n",
    "            model_lstm.zero_grad()\n",
    "            output =  model_lstm(inputs.double(), lengths)\n",
    "            loss = criterion(output.squeeze(), labels.double())\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        val_loss, (y_gold, y_pred) = evaluate_model(model_lstm, val_loader, criterion, regression=True, lstm=True)\n",
    "        \n",
    "        if val_loss < opt_val_loss:\n",
    "            opt_val_loss = val_loss\n",
    "            torch.save(model_lstm.state_dict(), save_string)\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "            \n",
    "        loss_values_train.append(np.mean(train_losses))\n",
    "        loss_values_val.append(val_loss)\n",
    "            \n",
    "        print(f'Epoch {epoch}: \\t Training Loss = {loss_values_train[-1]} \\t--\\t Validation Loss = {loss_values_val[-1]}')\n",
    "        if count > 7 and early_stopping:\n",
    "            print(\"Terminated due to early stopping\")\n",
    "            break\n",
    "            \n",
    "    if not early_stopping:\n",
    "        torch.save(model_lstm.state_dict(), save_string)\n",
    "        \n",
    "    return loss_values_train, loss_values_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T02:56:46.394215Z",
     "iopub.status.busy": "2022-02-28T02:56:46.393941Z",
     "iopub.status.idle": "2022-02-28T02:56:46.403875Z",
     "shell.execute_reply": "2022-02-28T02:56:46.403062Z",
     "shell.execute_reply.started": "2022-02-28T02:56:46.394187Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_lstm_model_multitask(test_loader, rnn_size, num_layers, save_file):\n",
    "    model_lstm = lab2_lstm.CustomLSTM(input_dim=n_mel,\n",
    "                                      rnn_size=rnn_size,\n",
    "                                      output_dim=1,\n",
    "                                      num_layers=num_layers,\n",
    "                                      bidirectional=True,\n",
    "                                      dropout=0).double().to(DEVICE)\n",
    "    \n",
    "    model_lstm.load_state_dict(torch.load(save_file))\n",
    "    \n",
    "    batch_size=5\n",
    "    test_losses = []\n",
    "    y_pred_test=[]\n",
    "    y_true=[]\n",
    "    model_lstm.eval()\n",
    "    \n",
    "    for inputs, labels,lengths in test_loader:\n",
    "        inputs, labels, lengths= inputs.to(DEVICE), labels.to(DEVICE), lengths.to(DEVICE)\n",
    "        output = model_lstm(inputs.double(), lengths)\n",
    "        y_pred_test.append(output.tolist())\n",
    "        y_true.append(labels.tolist())\n",
    "        \n",
    "    rho = scipy.stats.spearmanr(np.array(y_true).flatten(),np.array(y_pred_test).flatten()).correlation\n",
    "    print('\\nTest set: Spearman Correlation: {:.6f} \\n'.format(rho))\n",
    "    \n",
    "    true = np.array(y_true).flatten()\n",
    "    pred = np.array(y_pred_test).flatten()\n",
    "    \n",
    "    # Scatter Plots\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(true, pred)\n",
    "    plt.xlabel('y_true')\n",
    "    plt.ylabel('y_pred')\n",
    "    golden_line = np.linspace(0,1,1000)\n",
    "    plt.plot(golden_line,golden_line, '-', color='k')\n",
    "    plt.show()\n",
    "    \n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T23:20:59.55236Z",
     "iopub.status.busy": "2022-02-27T23:20:59.551944Z",
     "iopub.status.idle": "2022-02-27T23:30:45.06929Z",
     "shell.execute_reply": "2022-02-27T23:30:45.06852Z",
     "shell.execute_reply.started": "2022-02-27T23:20:59.552323Z"
    }
   },
   "outputs": [],
   "source": [
    "# valence\n",
    "train_losses_lstm_val, val_losses_lstm_val = train_lstm(train_loader_valence,\n",
    "                                                        val_loader_valence,\n",
    "                                                        \"lstm_valence\",\n",
    "                                                        early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T23:31:39.396891Z",
     "iopub.status.busy": "2022-02-27T23:31:39.39658Z",
     "iopub.status.idle": "2022-02-27T23:31:41.904928Z",
     "shell.execute_reply": "2022-02-27T23:31:41.904076Z",
     "shell.execute_reply.started": "2022-02-27T23:31:39.396856Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm_valence_rho = test_lstm_model_multitask(val_loader_valence,\n",
    "                                             rnn_size=RNN_SIZE,\n",
    "                                             num_layers=NUM_LAYERS,\n",
    "                                             save_file=\"lstm_valence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:20:18.214578Z",
     "iopub.status.busy": "2022-02-28T01:20:18.214318Z",
     "iopub.status.idle": "2022-02-28T01:29:58.789819Z",
     "shell.execute_reply": "2022-02-28T01:29:58.779712Z",
     "shell.execute_reply.started": "2022-02-28T01:20:18.214547Z"
    }
   },
   "outputs": [],
   "source": [
    "# energy\n",
    "train_losses_lstm_energy, val_losses_lstm_energy = train_lstm(train_loader_energy,\n",
    "                                                        val_loader_energy,\n",
    "                                                        \"lstm_energy\",\n",
    "                                                        early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:31:25.744208Z",
     "iopub.status.busy": "2022-02-28T01:31:25.743932Z",
     "iopub.status.idle": "2022-02-28T01:31:28.488114Z",
     "shell.execute_reply": "2022-02-28T01:31:28.486549Z",
     "shell.execute_reply.started": "2022-02-28T01:31:25.744175Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm_energy_rho = test_lstm_model_multitask(val_loader_energy,\n",
    "                                             rnn_size=RNN_SIZE,\n",
    "                                             num_layers=NUM_LAYERS,\n",
    "                                             save_file=\"lstm_energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T23:59:43.274875Z",
     "iopub.status.busy": "2022-02-27T23:59:43.274619Z",
     "iopub.status.idle": "2022-02-28T00:09:26.482877Z",
     "shell.execute_reply": "2022-02-28T00:09:26.482118Z",
     "shell.execute_reply.started": "2022-02-27T23:59:43.274846Z"
    }
   },
   "outputs": [],
   "source": [
    "# dancability\n",
    "train_losses_lstm_dance, val_losses_lstm_dance = train_lstm(train_loader_dancability,\n",
    "                                                        val_loader_dancability,\n",
    "                                                        \"lstm_dancability\",\n",
    "                                                        early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:09:26.484859Z",
     "iopub.status.busy": "2022-02-28T00:09:26.484516Z",
     "iopub.status.idle": "2022-02-28T00:09:28.891773Z",
     "shell.execute_reply": "2022-02-28T00:09:28.890949Z",
     "shell.execute_reply.started": "2022-02-28T00:09:26.48482Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm_dancability_rho = test_lstm_model_multitask(val_loader_dancability,\n",
    "                                                 rnn_size=RNN_SIZE,\n",
    "                                                 num_layers=NUM_LAYERS,\n",
    "                                                 save_file=\"lstm_dancability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:34:48.260601Z",
     "iopub.status.busy": "2022-02-28T01:34:48.260333Z",
     "iopub.status.idle": "2022-02-28T01:34:48.268839Z",
     "shell.execute_reply": "2022-02-28T01:34:48.264951Z",
     "shell.execute_reply.started": "2022-02-28T01:34:48.260572Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.mean([lstm_valence_rho, lstm_energy_rho, lstm_dancability_rho]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T02:17:14.410788Z",
     "iopub.status.busy": "2022-02-28T02:17:14.410538Z",
     "iopub.status.idle": "2022-02-28T02:17:52.743786Z",
     "shell.execute_reply": "2022-02-28T02:17:52.742893Z",
     "shell.execute_reply.started": "2022-02-28T02:17:14.410758Z"
    }
   },
   "outputs": [],
   "source": [
    "# energy training\n",
    "train_loss_energy, _ = train_cnn(train_loader = train_loader_energy,\n",
    "                                   val_loader = val_loader_energy,\n",
    "                                   save_string=\"step9\",\n",
    "                                   epochs=10,\n",
    "                                   regression=True,\n",
    "                                   early_stopping=True,\n",
    "                                   transfer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T02:17:52.745776Z",
     "iopub.status.busy": "2022-02-28T02:17:52.745523Z",
     "iopub.status.idle": "2022-02-28T02:17:53.79867Z",
     "shell.execute_reply": "2022-02-28T02:17:53.798034Z",
     "shell.execute_reply.started": "2022-02-28T02:17:52.745741Z"
    }
   },
   "outputs": [],
   "source": [
    "energy_spear_step9 = test_cnn_model_multitask(val_loader_energy, \"step9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Multitask Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:54:40.686131Z",
     "iopub.status.busy": "2022-02-28T22:54:40.685112Z",
     "iopub.status.idle": "2022-02-28T22:54:40.696554Z",
     "shell.execute_reply": "2022-02-28T22:54:40.695093Z",
     "shell.execute_reply.started": "2022-02-28T22:54:40.686081Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLoss(nn.Module):\n",
    "    def forward(self, y_gold, y_pred):\n",
    "        gold_valence = y_gold[:, 0]\n",
    "        gold_energy  = y_gold[:, 1]\n",
    "        gold_dance   = y_gold[:, 2]\n",
    "        \n",
    "        pred_valence = y_pred[:, 0]\n",
    "        pred_energy  = y_pred[:, 1]\n",
    "        pred_dance   = y_pred[:, 2]\n",
    "        \n",
    "        valence_loss = nn.MSELoss()(gold_valence, pred_valence)\n",
    "        energy_loss  = nn.MSELoss()(gold_energy,  pred_energy)\n",
    "        dance_loss   = nn.MSELoss()(gold_dance,   pred_dance)\n",
    "        \n",
    "        return valence_loss + energy_loss + dance_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:54:40.803965Z",
     "iopub.status.busy": "2022-02-28T22:54:40.803668Z",
     "iopub.status.idle": "2022-02-28T22:55:05.968755Z",
     "shell.execute_reply": "2022-02-28T22:55:05.967914Z",
     "shell.execute_reply.started": "2022-02-28T22:54:40.803935Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_dataset = multitask_dataset.MultitaskDataset(multitask_dir,\n",
    "                                                   train=True,\n",
    "                                                   class_mapping=dataset.CLASS_MAPPING,\n",
    "                                                   max_length=-1,\n",
    "                                                   regression=True\n",
    "                                                  )\n",
    "\n",
    "# train and validation sets\n",
    "train_loader_multi, val_loader_multi = dataset2.torch_train_val_split(multi_dataset,\n",
    "                                                                      batch_train=32,\n",
    "                                                                      batch_eval=32,\n",
    "                                                                      val_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:55:05.970958Z",
     "iopub.status.busy": "2022-02-28T22:55:05.970585Z",
     "iopub.status.idle": "2022-02-28T22:55:05.980485Z",
     "shell.execute_reply": "2022-02-28T22:55:05.978461Z",
     "shell.execute_reply.started": "2022-02-28T22:55:05.97091Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model2(model, dataloader, criterion):\n",
    "    model.eval() # switch to evaluation mode: disable dropout\n",
    "    overall_loss = 0.0\n",
    "    DEVICE = next(model.parameters()).device # set DEVICE to the model's predefined device\n",
    "    \n",
    "    y_pred = [] # predicted labels\n",
    "    y_gold = [] # gold labels\n",
    "    \n",
    "    with torch.no_grad(): # do not compute gradients\n",
    "        for idx, batch in enumerate(dataloader, 1):\n",
    "            \n",
    "            inputs  = batch[0].to(DEVICE).float()\n",
    "            labels  = batch[1].to(DEVICE).float()\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds.squeeze(), labels)\n",
    "            prediction = y_preds\n",
    "            \n",
    "            overall_loss += loss.data.item()\n",
    "            \n",
    "            y_pred.append(prediction.cpu().numpy())\n",
    "            y_gold.append(labels.cpu().numpy())\n",
    "\n",
    "    return overall_loss/idx, (y_gold, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:55:05.982771Z",
     "iopub.status.busy": "2022-02-28T22:55:05.982193Z",
     "iopub.status.idle": "2022-02-28T22:55:05.998219Z",
     "shell.execute_reply": "2022-02-28T22:55:05.997454Z",
     "shell.execute_reply.started": "2022-02-28T22:55:05.982705Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_cnn2(train_loader, val_loader, save_string, epochs, early_stopping=True, transfer=False):\n",
    "    \n",
    "    model_cnn = CustomCNN().to(DEVICE).float()\n",
    "    \n",
    "    model_cnn._fc_module = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=20480, out_features=3) #1 0240\n",
    "        ).to(DEVICE)\n",
    "    \n",
    "\n",
    "    lr=LR\n",
    "    criterion = MyLoss()\n",
    "    optimizer = torch.optim.Adam(model_cnn.parameters(), lr=lr, weight_decay=0.0001)\n",
    "\n",
    "    train_loss_min = np.Inf\n",
    "    loss_values_train = []\n",
    "    loss_values_val = []\n",
    "    count=0\n",
    "    \n",
    "    opt_val_loss = np.Inf\n",
    "    \n",
    "    model_cnn.train()    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        running_loss_train=0.0\n",
    "        train_losses=[]\n",
    "        for inputs, labels,lengths in train_loader:\n",
    "            inputs, labels, lengths= inputs.to(DEVICE), labels.to(DEVICE), lengths.to(DEVICE)\n",
    "            model_cnn.zero_grad()\n",
    "            output =  model_cnn(inputs.float())\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        val_loss, (y_gold, y_pred) = evaluate_model2(model_cnn, val_loader, criterion)\n",
    "        \n",
    "        if val_loss < opt_val_loss:\n",
    "            opt_val_loss = val_loss\n",
    "            torch.save(model_cnn.state_dict(), save_string)\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "            \n",
    "        loss_values_train.append(np.mean(train_losses))\n",
    "        loss_values_val.append(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch}: \\t Training Loss = {loss_values_train[-1]} \\t--\\t Validation Loss = {loss_values_val[-1]}')\n",
    "        if count > 10 and early_stopping:\n",
    "            print(\"Terminated due to early stopping\")\n",
    "            break\n",
    "            \n",
    "    if not early_stopping:\n",
    "        torch.save(model_cnn.state_dict(), save_string)\n",
    "            \n",
    "    return loss_values_train, loss_values_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:55:06.000479Z",
     "iopub.status.busy": "2022-02-28T22:55:06.000097Z",
     "iopub.status.idle": "2022-02-28T22:58:04.841828Z",
     "shell.execute_reply": "2022-02-28T22:58:04.841038Z",
     "shell.execute_reply.started": "2022-02-28T22:55:06.000439Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_values_train, loss_values_val = train_cnn2(train_loader_multi,\n",
    "                                                val_loader_multi,\n",
    "                                                \"step10\",\n",
    "                                                epochs=30,\n",
    "                                                early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:58:19.627541Z",
     "iopub.status.busy": "2022-02-28T22:58:19.627091Z",
     "iopub.status.idle": "2022-02-28T22:58:19.637853Z",
     "shell.execute_reply": "2022-02-28T22:58:19.637178Z",
     "shell.execute_reply.started": "2022-02-28T22:58:19.627501Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_cnn_model_multitask(test_loader, save_file):\n",
    "    \n",
    "    model_cnn = CustomCNN().to(DEVICE)\n",
    "    model_cnn._fc_module = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=20480, out_features=3) #10240\n",
    "        ).to(DEVICE)\n",
    "    \n",
    "    model_cnn.load_state_dict(torch.load(save_file))\n",
    "    \n",
    "    test_losses = []\n",
    "    y_pred_test=[]\n",
    "    y_true=[]\n",
    "    model_cnn.eval()\n",
    "    \n",
    "    for inputs, labels,lengths in test_loader:\n",
    "        inputs,labels,lengths= inputs.to(DEVICE), labels.to(DEVICE), lengths.to(DEVICE)\n",
    "        output = model_cnn(inputs.float())\n",
    "        y_pred_test.append(output.data.tolist())\n",
    "        y_true.append(labels.tolist())\n",
    "        \n",
    "    convenient_y_pred_test = np.concatenate(np.array(y_pred_test))\n",
    "    convenient_y_true = np.concatenate(np.array(y_true))\n",
    "    \n",
    "    rho_valence = scipy.stats.spearmanr(convenient_y_pred_test[:, 0], convenient_y_true[:, 0]).correlation\n",
    "    rho_energy  = scipy.stats.spearmanr(convenient_y_pred_test[:, 1], convenient_y_true[:, 1]).correlation\n",
    "    rho_dance   = scipy.stats.spearmanr(convenient_y_pred_test[:, 2], convenient_y_true[:, 2]).correlation\n",
    "    mean = np.mean([rho_valence, rho_energy, rho_dance])\n",
    "    \n",
    "    print(rho_valence)\n",
    "    print(rho_energy)\n",
    "    print(rho_dance)\n",
    "    print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:58:23.257362Z",
     "iopub.status.busy": "2022-02-28T22:58:23.257108Z",
     "iopub.status.idle": "2022-02-28T22:58:23.829338Z",
     "shell.execute_reply": "2022-02-28T22:58:23.828679Z",
     "shell.execute_reply.started": "2022-02-28T22:58:23.257332Z"
    }
   },
   "outputs": [],
   "source": [
    "test_cnn_model_multitask(val_loader_multi, \"step10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:58:30.083341Z",
     "iopub.status.busy": "2022-02-28T22:58:30.08309Z",
     "iopub.status.idle": "2022-02-28T22:58:30.105101Z",
     "shell.execute_reply": "2022-02-28T22:58:30.104217Z",
     "shell.execute_reply.started": "2022-02-28T22:58:30.08331Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "\n",
    "\n",
    "def torch_train_val_split(\n",
    "    dataset, batch_train, batch_eval, val_size=0.2, shuffle=True, seed=420\n",
    "):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def read_spectrogram(spectrogram_file, chroma=True):\n",
    "    spectrograms = np.load(spectrogram_file)\n",
    "    return spectrograms.T\n",
    "\n",
    "\n",
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])\n",
    "\n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[: self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "\n",
    "class KaggleDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, path, class_mapping=None, max_length=-1, regression=None\n",
    "    ):\n",
    "        t = \"test\"\n",
    "        p = os.path.join(path, t)\n",
    "        self.regression = regression\n",
    "\n",
    "        self.files = [] \n",
    "        self.feats = [] \n",
    "\n",
    "        for f in os.listdir(p):\n",
    "            self.feats.append(read_spectrogram(os.path.join(p, f)))\n",
    "            self.files.append(f.split('.')[0])\n",
    "\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        length = min(self.lengths[item], self.max_length)\n",
    "        return self.zero_pad_and_stack(self.feats[item]), self.files[item], length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:58:32.926967Z",
     "iopub.status.busy": "2022-02-28T22:58:32.926393Z",
     "iopub.status.idle": "2022-02-28T22:58:42.605787Z",
     "shell.execute_reply": "2022-02-28T22:58:42.605019Z",
     "shell.execute_reply.started": "2022-02-28T22:58:32.926922Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_test_dataset = KaggleDataset(multitask_dir,\n",
    "                                      class_mapping=dataset.CLASS_MAPPING\n",
    "                                      )\n",
    "\n",
    "kaggle_test_dataloader, _ = torch_train_val_split(dataset=kaggle_test_dataset,\n",
    "                                               batch_train=32,\n",
    "                                               batch_eval=32,\n",
    "                                               val_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:58:42.613273Z",
     "iopub.status.busy": "2022-02-28T22:58:42.612898Z",
     "iopub.status.idle": "2022-02-28T22:58:42.625152Z",
     "shell.execute_reply": "2022-02-28T22:58:42.624434Z",
     "shell.execute_reply.started": "2022-02-28T22:58:42.613236Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_cnn_2(test_loader, model_dir):\n",
    "    \n",
    "    model_cnn = CustomCNN().to(DEVICE).float()\n",
    "    model_cnn._fc_module = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=20480, out_features=3) # 10240\n",
    "        ).to(DEVICE)\n",
    "    \n",
    "    model_cnn.load_state_dict(torch.load(model_dir))\n",
    "    \n",
    "    test_losses = []\n",
    "    y_pred_test=[]\n",
    "    y_true=[]\n",
    "    filenames = []\n",
    "    all_preds = []\n",
    "    model_cnn.eval()\n",
    "    filenames = []\n",
    "    \n",
    "    counterr = 0\n",
    "    for batch in test_loader:\n",
    "        inputs, filename, _ = batch\n",
    "        \n",
    "        for file in filename:\n",
    "            filenames.append(file)\n",
    "            \n",
    "        inputs = inputs.to(DEVICE).float()\n",
    "        output = model_cnn(inputs)\n",
    "        \n",
    "        y_pred_test.append(output.cpu().detach().numpy()) # output.data.tolist()\n",
    "    \n",
    "    pred = np.concatenate(y_pred_test)    \n",
    "    \n",
    "    return filenames, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:58:42.627161Z",
     "iopub.status.busy": "2022-02-28T22:58:42.62685Z",
     "iopub.status.idle": "2022-02-28T22:58:43.872346Z",
     "shell.execute_reply": "2022-02-28T22:58:43.87145Z",
     "shell.execute_reply.started": "2022-02-28T22:58:42.627126Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames, pred = test_cnn_2(kaggle_test_dataloader, \"step10\")\n",
    "toKaggle = np.zeros((375,4))\n",
    "toKaggle[:,0] = filenames\n",
    "toKaggle[:,1:] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T22:58:43.87496Z",
     "iopub.status.busy": "2022-02-28T22:58:43.874683Z",
     "iopub.status.idle": "2022-02-28T22:58:43.891963Z",
     "shell.execute_reply": "2022-02-28T22:58:43.891178Z",
     "shell.execute_reply.started": "2022-02-28T22:58:43.87492Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/working/kaggle_sub.csv', 'w', newline='\\n') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Id.fused.full.npy.gz\", \"valence\", \"energy\", \"danceability\"])\n",
    "        for i in range(375):\n",
    "            tt = []\n",
    "            tt.append(str(int(toKaggle[i][0]))+'.fused.full.npy.gz')\n",
    "            tt.append(str(toKaggle[i][1]))\n",
    "            tt.append(str(toKaggle[i][2]))\n",
    "            tt.append(str(toKaggle[i][3]))\n",
    "            writer.writerow(tt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
